{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777088e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting tqdm (from opendatasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting kaggle (from opendatasets)\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opendatasets) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Collecting bleach (from kaggle->opendatasets)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle->opendatasets) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle->opendatasets) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle->opendatasets) (3.10)\n",
      "Collecting protobuf (from kaggle->opendatasets)\n",
      "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle->opendatasets)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Collecting setuptools>=21.0.0 (from kaggle->opendatasets)\n",
      "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle->opendatasets)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle->opendatasets) (2.4.0)\n",
      "Collecting webencodings (from kaggle->opendatasets)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "Downloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 799.2 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 799.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 588.4 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 588.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.3 MB 629.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 642.6 kB/s eta 0:00:00\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, tqdm, setuptools, python-slugify, protobuf, bleach, kaggle, opendatasets\n",
      "\n",
      "   ---------------------------------------- 0/9 [webencodings]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [tqdm]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ------------- -------------------------- 3/9 [setuptools]\n",
      "   ----------------- ---------------------- 4/9 [python-slugify]\n",
      "   ----------------- ---------------------- 4/9 [python-slugify]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   ---------------------- ----------------- 5/9 [protobuf]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   -------------------------- ------------- 6/9 [bleach]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ------------------------------- -------- 7/9 [kaggle]\n",
      "   ----------------------------------- ---- 8/9 [opendatasets]\n",
      "   ----------------------------------- ---- 8/9 [opendatasets]\n",
      "   ---------------------------------------- 9/9 [opendatasets]\n",
      "\n",
      "Successfully installed bleach-6.2.0 kaggle-1.7.4.2 opendatasets-0.1.22 protobuf-6.30.2 python-slugify-8.0.4 setuptools-79.0.1 text-unidecode-1.3 tqdm-4.67.1 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script slugify.exe is installed in 'c:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script kaggle.exe is installed in 'c:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10aad369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (79.0.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ali\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ali\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb71af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "# 1. Lazy load only needed columns\n",
    "ddf = dd.read_csv(\"Europe towers.csv\",\n",
    "                  usecols=[\"LON\",\"LAT\",\"Country\",\"Continent\"],\n",
    "                  dtype={\"Continent\":\"category\",\"Country\":\"category\"})\n",
    "\n",
    "# 2. Filter to Slovenia (still lazy)\n",
    "ddf_sl = ddf[ddf.Country==\"Slovenia\"]\n",
    "\n",
    "# 3. Persist to Parquet for super-fast re-loads later\n",
    "ddf_sl.to_parquet(\"slovenia_towers.parquet\", engine=\"pyarrow\",\n",
    "                  compression=\"snappy\", write_index=False)\n",
    "\n",
    "df = pd.read_parquet(\"slovenia_towers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4b5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         LON        LAT   Country Continent\n",
      "0  15.650914  46.655765  Slovenia    Europe\n",
      "1  15.724667  46.582526  Slovenia    Europe\n",
      "2  15.652736  46.642071  Slovenia    Europe\n",
      "3  15.650014  46.656214  Slovenia    Europe\n",
      "4  15.660907  46.619164  Slovenia    Europe\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & Load Data\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# 1a. Load your ping DataFrame (example: all pings for one device)\n",
    "#    Must have columns: lat, lon, datetime (datetime64[ns])\n",
    "# df_pings = pd.read_parquet(\"df_user_all.parquet\")  \n",
    "#    — or however you have it loaded\n",
    "\n",
    "# 1b. Load Slovenia cell-tower locations\n",
    "df_towers = pd.read_parquet(\"slovenia_towers.parquet\")  # columns: LAT, LON\n",
    "\n",
    "print(df_towers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396b2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top device in sample: 136b30f450ef55cf22afcc5e6213c5f7f664766324c1057fa6edef424409b6a4\n",
      "Loaded 3153 pings for device 136b30f450ef55cf22afcc5e6213c5f7f664766324c1057fa6edef424409b6a4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceid</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136b30f450ef55cf22afcc5e6213c5f7f664766324c105...</td>\n",
       "      <td>27.03.2023</td>\n",
       "      <td>20:00:04</td>\n",
       "      <td>46.05167</td>\n",
       "      <td>14.50667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136b30f450ef55cf22afcc5e6213c5f7f664766324c105...</td>\n",
       "      <td>27.03.2023</td>\n",
       "      <td>20:00:07</td>\n",
       "      <td>46.05167</td>\n",
       "      <td>14.50667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136b30f450ef55cf22afcc5e6213c5f7f664766324c105...</td>\n",
       "      <td>27.03.2023</td>\n",
       "      <td>20:00:19</td>\n",
       "      <td>46.05167</td>\n",
       "      <td>14.50667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136b30f450ef55cf22afcc5e6213c5f7f664766324c105...</td>\n",
       "      <td>27.03.2023</td>\n",
       "      <td>20:00:22</td>\n",
       "      <td>46.05167</td>\n",
       "      <td>14.50667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136b30f450ef55cf22afcc5e6213c5f7f664766324c105...</td>\n",
       "      <td>27.03.2023</td>\n",
       "      <td>20:00:29</td>\n",
       "      <td>46.05167</td>\n",
       "      <td>14.50667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            deviceid        date      time  \\\n",
       "0  136b30f450ef55cf22afcc5e6213c5f7f664766324c105...  27.03.2023  20:00:04   \n",
       "1  136b30f450ef55cf22afcc5e6213c5f7f664766324c105...  27.03.2023  20:00:07   \n",
       "2  136b30f450ef55cf22afcc5e6213c5f7f664766324c105...  27.03.2023  20:00:19   \n",
       "3  136b30f450ef55cf22afcc5e6213c5f7f664766324c105...  27.03.2023  20:00:22   \n",
       "4  136b30f450ef55cf22afcc5e6213c5f7f664766324c105...  27.03.2023  20:00:29   \n",
       "\n",
       "        lat       lon  \n",
       "0  46.05167  14.50667  \n",
       "1  46.05167  14.50667  \n",
       "2  46.05167  14.50667  \n",
       "3  46.05167  14.50667  \n",
       "4  46.05167  14.50667  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell A: Find the device with the most pings in a small head sample\n",
    "from fastparquet import ParquetFile\n",
    "import pandas as pd\n",
    "\n",
    "pf      = ParquetFile(\"training_set/20230327.parquet\")\n",
    "# read only deviceid for the first 100k rows\n",
    "df_head = pf.head(nrows=100_000, columns=[\"deviceid\"])\n",
    "# pick the most frequent device in that sample\n",
    "top_dev = df_head[\"deviceid\"].value_counts().idxmax()\n",
    "print(f\"Top device in sample: {top_dev}\")\n",
    "\n",
    "# Cell B: Load every ping for that top device from the full day (≈130 M rows)\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# only load the columns we care about, and push the filter into the Parquet reader\n",
    "ddf = dd.read_parquet(\n",
    "    \"training_set/20230327.parquet\",\n",
    "    columns=[\"deviceid\",\"date\",\"time\",\"lat\",\"lon\"],\n",
    "    filters=[(\"deviceid\", \"=\", top_dev)]\n",
    ")\n",
    "\n",
    "# now compute into pandas — this will only pull in that one device’s rows\n",
    "df_pings = ddf.compute()\n",
    "print(f\"Loaded {len(df_pings)} pings for device {top_dev}\")\n",
    "\n",
    "# Peek\n",
    "df_pings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc14f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Build k-d Tree & Compute Nearest-Tower Distances\n",
    "# --------------------------------------------------------\n",
    "# 2a. Build spatial index on towers\n",
    "tower_coords = np.vstack([df_towers[\"LAT\"], df_towers[\"LON\"]]).T\n",
    "tower_tree   = cKDTree(tower_coords)\n",
    "\n",
    "# 2b. Query each ping’s 3 nearest towers (d1 ≤ d2 ≤ d3)\n",
    "ping_coords = np.vstack([df_pings[\"lat\"], df_pings[\"lon\"]]).T\n",
    "dists, idxs = tower_tree.query(ping_coords, k=3)\n",
    "\n",
    "# 2c. Attach distances & nearest-tower index as features\n",
    "df_pings[\"d1_m\"]    = dists[:,0]\n",
    "df_pings[\"d2_m\"]    = dists[:,1]\n",
    "df_pings[\"d3_m\"]    = dists[:,2]\n",
    "df_pings[\"zone_id\"] = idxs[:,0]    # Voronoi cell = nearest tower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5007a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 pings (>3km); 3153 remain\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Outlier Removal (d1 > 3 km)\n",
    "# -----------------------------------\n",
    "# Drop any ping further than 3 000 m from its nearest tower\n",
    "mask_valid = df_pings[\"d1_m\"] <= 3000\n",
    "df_clean   = df_pings.loc[mask_valid].copy()\n",
    "print(f\"Dropped {len(df_pings)-len(df_clean)} pings (>3km); {len(df_clean)} remain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e1d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     db_labels.append(pd.Series(lbls, index=grp.index))\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 4b. Combine back into a single column\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_cluster\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = pd.concat(db_labels).sort_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5263\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[32m   5262\u001b[39m         value = Series(value)\n\u001b[32m-> \u001b[39m\u001b[32m5263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m   5266\u001b[39m     com.require_length_match(value, \u001b[38;5;28mself\u001b[39m.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:12692\u001b[39m, in \u001b[36m_reindex_for_setitem\u001b[39m\u001b[34m(value, index)\u001b[39m\n\u001b[32m  12688\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m  12689\u001b[39m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[32m  12690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value.index.is_unique:\n\u001b[32m  12691\u001b[39m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12692\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m  12694\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m  12695\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mincompatible index of inserted column with frame index\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  12696\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m  12697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:12687\u001b[39m, in \u001b[36m_reindex_for_setitem\u001b[39m\u001b[34m(value, index)\u001b[39m\n\u001b[32m  12685\u001b[39m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[32m  12686\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m12687\u001b[39m     reindexed_value = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m._values\n\u001b[32m  12688\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m  12689\u001b[39m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[32m  12690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value.index.is_unique:\n\u001b[32m  12691\u001b[39m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[39m, in \u001b[36mSeries.reindex\u001b[39m\u001b[34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5136\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5137\u001b[39m     NDFrame.reindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m   5138\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5151\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5152\u001b[39m ) -> Series:\n\u001b[32m-> \u001b[39m\u001b[32m5153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5607\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5609\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5610\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5612\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5630\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5632\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5633\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5637\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5638\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5639\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5640\u001b[39m     fill_value=fill_value,\n\u001b[32m   5641\u001b[39m     copy=copy,\n\u001b[32m   5642\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5643\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_unique:\n\u001b[32m   4428\u001b[39m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4431\u001b[39m     indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "# Cell 4: Zone-Aware Clustering\n",
    "# -----------------------------\n",
    "# For each tower-zone, run DBSCAN with a zone-specific eps\n",
    "# (you can pick eps per zone based on local density; here we use 100 m)\n",
    "# 0. Make sure df_clean has a clean integer index\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# 1. Prepare an output array of “unassigned” labels\n",
    "stop_labels = np.full(len(df_clean), -1, dtype=int)\n",
    "\n",
    "# 2. Zone-aware DBSCAN\n",
    "eps_zone = 0.0009  # ~100 m in radians for haversine\n",
    "for zone_id, grp in df_clean.groupby(\"zone_id\"):\n",
    "    # lat/lon in radians\n",
    "    coords_rad = np.radians(grp[[\"lat\", \"lon\"]].to_numpy())\n",
    "    db = DBSCAN(eps=eps_zone, min_samples=5, metric=\"haversine\")\n",
    "    labels = db.fit_predict(coords_rad)\n",
    "    \n",
    "    # assign back by integer index\n",
    "    stop_labels[grp.index] = labels\n",
    "\n",
    "# 3. Add to DataFrame\n",
    "df_clean[\"stop_cluster\"] = stop_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Zone-Level Speed Binning\n",
    "# -------------------------------\n",
    "# Compute instantaneous speeds if you have datetime\n",
    "df_clean = df_clean.sort_values(\"datetime\")\n",
    "delta_t = df_clean[\"datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "# haversine distance\n",
    "lat_r = np.radians(df_clean[\"lat\"]); lon_r = np.radians(df_clean[\"lon\"])\n",
    "dlat  = lat_r.diff().fillna(0); dlon = lon_r.diff().fillna(0)\n",
    "a     = np.sin(dlat/2)**2 + np.cos(lat_r.shift())*np.cos(lat_r)*np.sin(dlon/2)**2\n",
    "dist  = 2*6371000*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "speeds = (dist / delta_t).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "df_clean[\"speed_m_s\"] = speeds\n",
    "\n",
    "# Aggregate per zone: min/max/avg speed and dwell time\n",
    "zone_stats = (\n",
    "    df_clean\n",
    "      .groupby(\"zone_id\")\n",
    "      .agg(\n",
    "        min_speed=(\"speed_m_s\",\"min\"),\n",
    "        max_speed=(\"speed_m_s\",\"max\"),\n",
    "        avg_speed=(\"speed_m_s\",\"mean\"),\n",
    "        dwell_time=(\"delta_t\",\"sum\")\n",
    "      )\n",
    ")\n",
    "zone_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c3c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
