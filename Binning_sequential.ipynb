{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466db18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/hpc/home/jo83525/.local/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025-05-20 18:15:35 INFO: Processing data_denoised/20230331.parquet\n",
      "2025-05-20 18:16:07 INFO: Adding spatial bin\n",
      "2025-05-20 18:19:12 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:20:01 INFO: Wrote data_binned/20230331.parquet\n",
      "2025-05-20 18:20:01 INFO: Processing data_denoised/20230328.parquet\n",
      "2025-05-20 18:20:29 INFO: Adding spatial bin\n",
      "2025-05-20 18:23:33 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:24:21 INFO: Wrote data_binned/20230328.parquet\n",
      "2025-05-20 18:24:21 INFO: Processing data_denoised/20230327.parquet\n",
      "2025-05-20 18:24:49 INFO: Adding spatial bin\n",
      "2025-05-20 18:27:50 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:28:39 INFO: Wrote data_binned/20230327.parquet\n",
      "2025-05-20 18:28:39 INFO: Processing data_denoised/20230401.parquet\n",
      "2025-05-20 18:29:04 INFO: Adding spatial bin\n",
      "2025-05-20 18:31:46 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:32:29 INFO: Wrote data_binned/20230401.parquet\n",
      "2025-05-20 18:32:29 INFO: Processing data_denoised/20230329.parquet\n",
      "2025-05-20 18:32:59 INFO: Adding spatial bin\n",
      "2025-05-20 18:36:06 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:36:55 INFO: Wrote data_binned/20230329.parquet\n",
      "2025-05-20 18:36:55 INFO: Processing data_denoised/20230330.parquet\n",
      "2025-05-20 18:37:26 INFO: Adding spatial bin\n",
      "2025-05-20 18:40:35 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:41:25 INFO: Wrote data_binned/20230330.parquet\n",
      "2025-05-20 18:41:25 INFO: Processing data_denoised/20230402.parquet\n",
      "2025-05-20 18:41:49 INFO: Adding spatial bin\n",
      "2025-05-20 18:44:19 INFO: Adding time bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.colums= Index(['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change',\n",
      "       'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:44:58 INFO: Wrote data_binned/20230402.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# ───────────────────────────── config ──────────────────────────────\n",
    "IN_DIR            = Path(\"data_denoised\")     # denoised input\n",
    "OUT_DIR           = Path(\"data_binned\")       # enriched output\n",
    "GRID_FILE         = Path(\"maps/minimalist_coning.geojson\")\n",
    "TIME_BIN_MINUTES  = 60\n",
    "# TOWER_FILE        = Path(\"data/slovenia_towers.parquet\")\n",
    "# MAX_RADIUS_M      = 300    # accept towers within this radius\n",
    "\n",
    "# # ─────────────────────── towers (once) ────────────────────────────\n",
    "# tower_df  = pd.read_parquet(TOWER_FILE)\n",
    "# tower_gdf = gpd.GeoDataFrame(\n",
    "#     tower_df,\n",
    "#     geometry=gpd.points_from_xy(tower_df.LON, tower_df.LAT),\n",
    "#     crs=\"EPSG:4326\"\n",
    "# ).to_crs(\"EPSG:3857\")\n",
    "\n",
    "# tower_gdf[\"tower_id\"] = np.arange(len(tower_gdf), dtype=\"int32\")\n",
    "\n",
    "# # ─────────────────── helper: add nearest tower ────────────────────\n",
    "# def add_tower_id(df: pd.DataFrame,\n",
    "#                  max_radius_m: float = MAX_RADIUS_M) -> pd.DataFrame:\n",
    "#     # build point GeoDataFrame in metres\n",
    "#     pts = gpd.GeoDataFrame(\n",
    "#         df,\n",
    "#         geometry=gpd.points_from_xy(df.lon, df.lat),\n",
    "#         crs=\"EPSG:4326\"\n",
    "#     ).to_crs(\"EPSG:3857\")\n",
    "\n",
    "#     joined = gpd.sjoin_nearest(\n",
    "#         pts,\n",
    "#         tower_gdf[[\"tower_id\", \"geometry\"]],\n",
    "#         how=\"left\",\n",
    "#         max_distance=max_radius_m,\n",
    "#         distance_col=\"tower_dist_m\"\n",
    "#     )\n",
    "\n",
    "#     # ── collapse possible duplicates (one row per point) ──────────\n",
    "#     first = (joined\n",
    "#              .sort_index()                       # keep stable order\n",
    "#              .groupby(level=0)                   # original point index\n",
    "#              .first())\n",
    "\n",
    "#     df[\"tower_id\"]     = first[\"tower_id\"].to_numpy()\n",
    "#     df[\"tower_dist_m\"] = first[\"tower_dist_m\"].to_numpy()\n",
    "#     df[\"tower_ok\"]     = first[\"tower_id\"].notna()\n",
    "\n",
    "#     return df\n",
    "\n",
    "# ───────────────────────── logging setup ──────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# ───────────────────── other helper functions ─────────────────────\n",
    "CHUNK = 5_000_000                       # rows per slice\n",
    "\n",
    "_grid_gdf = gpd.read_file(GRID_FILE)\n",
    "if \"zone_id\" not in _grid_gdf.columns:\n",
    "    _grid_gdf[\"zone_id\"] = np.arange(len(_grid_gdf), dtype=\"int32\")\n",
    "_grid_gdf = _grid_gdf.to_crs(\"EPSG:4326\")      # WGS-84\n",
    "\n",
    "def add_zone_id(df: pd.DataFrame, chunk: int = 5_000_000) -> pd.DataFrame:\n",
    "    n = len(df)\n",
    "    zone_out = np.full(n, -1, dtype=np.int32)        # -1  → no polygon\n",
    "\n",
    "    for start in range(0, n, chunk):\n",
    "        end = min(start + chunk, n)\n",
    "\n",
    "        # build GeoDataFrame slice\n",
    "        pts = gpd.GeoDataFrame(\n",
    "            df.iloc[start:end],\n",
    "            geometry=gpd.points_from_xy(df.lon.iloc[start:end],\n",
    "                                        df.lat.iloc[start:end]),\n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "        joined = gpd.sjoin(\n",
    "            pts,\n",
    "            _grid_gdf[[\"zone_id\", \"geometry\"]],\n",
    "            how=\"left\",\n",
    "            predicate=\"within\"\n",
    "        )\n",
    "\n",
    "        # first match per original point\n",
    "        z = (joined\n",
    "             .groupby(level=0)[\"zone_id\"]\n",
    "             .first()\n",
    "             .dropna())                       # drop NaNs (unmatched)\n",
    "\n",
    "        idx_absolute = z.index.to_numpy(dtype=np.intp)\n",
    "        zone_out[idx_absolute] = z.to_numpy(dtype=np.int32)\n",
    "\n",
    "    df[\"zone_id\"] = zone_out\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_time_bin(df: pd.DataFrame,\n",
    "                 minutes: int = TIME_BIN_MINUTES) -> pd.DataFrame:\n",
    "    mins = df[\"datetime\"].dt.hour * 60 + df[\"datetime\"].dt.minute\n",
    "    df[\"time_bin\"] = (mins // minutes).astype(\"int16\")\n",
    "    return df\n",
    "\n",
    "# ─────────────────────────── main loop ────────────────────────────\n",
    "def main() -> None:\n",
    "    grid = gpd.read_file(GRID_FILE)\n",
    "    if \"zone_id\" not in grid.columns:\n",
    "        grid[\"zone_id\"] = np.arange(len(grid), dtype=\"int32\")\n",
    "\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for f in IN_DIR.glob(\"*.parquet\"):\n",
    "        logging.info(\"Processing %s\", f)\n",
    "        df = pd.read_parquet(f)\n",
    "\n",
    "        logging.info(\"Adding spatial bin\")\n",
    "        df = add_zone_id(df)          \n",
    "\n",
    "        logging.info(\"Adding time bin\")\n",
    "        df = add_time_bin(df)\n",
    "\n",
    "        print(f\"df.colums= {df.columns}\")\n",
    "\n",
    "        out_path = OUT_DIR / f.name\n",
    "        df.to_parquet(out_path, index=False, compression=\"snappy\")\n",
    "        logging.info(\"Wrote %s\", out_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1003c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4130154/710004746.py:17: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 20230327 ===\n",
      "{'binned': {'avg_pts_per_device': 205.08,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 522654,\n",
      "            'n_points': 107185452},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 205.08,\n",
      "                                       'before': 177.66,\n",
      "                                       'reduction_%': -15.43},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 522654,\n",
      "                              'before': 751168,\n",
      "                              'reduction_%': 30.42},\n",
      "                'n_points': {'after': 107185452,\n",
      "                             'before': 133453155,\n",
      "                             'reduction_%': 19.68}},\n",
      " 'raw': {'avg_pts_per_device': 177.66,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 751168,\n",
      "         'n_points': 133453155}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4130154/710004746.py:17: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 20230328 ===\n",
      "{'binned': {'avg_pts_per_device': 200.93,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 520348,\n",
      "            'n_points': 104552132},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 200.93,\n",
      "                                       'before': 174.33,\n",
      "                                       'reduction_%': -15.26},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 520348,\n",
      "                              'before': 749459,\n",
      "                              'reduction_%': 30.57},\n",
      "                'n_points': {'after': 104552132,\n",
      "                             'before': 130654297,\n",
      "                             'reduction_%': 19.98}},\n",
      " 'raw': {'avg_pts_per_device': 174.33,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 749459,\n",
      "         'n_points': 130654297}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4130154/710004746.py:17: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 20230329 ===\n",
      "{'binned': {'avg_pts_per_device': 204.4,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 529451,\n",
      "            'n_points': 108218727},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 204.4,\n",
      "                                       'before': 178.31,\n",
      "                                       'reduction_%': -14.63},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 529451,\n",
      "                              'before': 758892,\n",
      "                              'reduction_%': 30.23},\n",
      "                'n_points': {'after': 108218727,\n",
      "                             'before': 135320914,\n",
      "                             'reduction_%': 20.03}},\n",
      " 'raw': {'avg_pts_per_device': 178.31,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 758892,\n",
      "         'n_points': 135320914}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4130154/710004746.py:17: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 20230330 ===\n",
      "{'binned': {'avg_pts_per_device': 202.03,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 536732,\n",
      "            'n_points': 108437587},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 202.03,\n",
      "                                       'before': 176.74,\n",
      "                                       'reduction_%': -14.31},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 536732,\n",
      "                              'before': 768525,\n",
      "                              'reduction_%': 30.16},\n",
      "                'n_points': {'after': 108437587,\n",
      "                             'before': 135827994,\n",
      "                             'reduction_%': 20.17}},\n",
      " 'raw': {'avg_pts_per_device': 176.74,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 768525,\n",
      "         'n_points': 135827994}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4130154/710004746.py:17: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 20230331 ===\n",
      "{'binned': {'avg_pts_per_device': 188.06,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 569004,\n",
      "            'n_points': 107006496},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 188.06,\n",
      "                                       'before': 167.63,\n",
      "                                       'reduction_%': -12.19},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 569004,\n",
      "                              'before': 802897,\n",
      "                              'reduction_%': 29.13},\n",
      "                'n_points': {'after': 107006496,\n",
      "                             'before': 134586862,\n",
      "                             'reduction_%': 20.49}},\n",
      " 'raw': {'avg_pts_per_device': 167.63,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 802897,\n",
      "         'n_points': 134586862}}\n",
      "\n",
      "=== 20230401 ===\n",
      "{'binned': {'avg_pts_per_device': 180.41,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 520165,\n",
      "            'n_points': 93842386},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 180.41,\n",
      "                                       'before': 155.92,\n",
      "                                       'reduction_%': -15.71},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 520165,\n",
      "                              'before': 751629,\n",
      "                              'reduction_%': 30.79},\n",
      "                'n_points': {'after': 93842386,\n",
      "                             'before': 117190239,\n",
      "                             'reduction_%': 19.92}},\n",
      " 'raw': {'avg_pts_per_device': 155.92,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 751629,\n",
      "         'n_points': 117190239}}\n",
      "\n",
      "=== 20230402 ===\n",
      "{'binned': {'avg_pts_per_device': 191.85,\n",
      "            'hours_covered': 24.0,\n",
      "            'n_devices': 464966,\n",
      "            'n_points': 89204599},\n",
      " 'comparison': {'avg_pts_per_device': {'after': 191.85,\n",
      "                                       'before': 159.65,\n",
      "                                       'reduction_%': -20.17},\n",
      "                'hours_covered': {'after': 24.0,\n",
      "                                  'before': 24.0,\n",
      "                                  'reduction_%': 0.0},\n",
      "                'n_devices': {'after': 464966,\n",
      "                              'before': 693142,\n",
      "                              'reduction_%': 32.92},\n",
      "                'n_points': {'after': 89204599,\n",
      "                             'before': 110660627,\n",
      "                             'reduction_%': 19.39}},\n",
      " 'raw': {'avg_pts_per_device': 159.65,\n",
      "         'hours_covered': 24.0,\n",
      "         'n_devices': 693142,\n",
      "         'n_points': 110660627}}\n",
      "⚠️  missing binned file for slovenia_towers.parquet\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pprint import pprint\n",
    "\n",
    "RAW_DIR = Path(\"data\")\n",
    "BIN_DIR = Path(\"data_binned\")\n",
    "\n",
    "def columns_in_file(path):\n",
    "    return pq.ParquetFile(path).schema_arrow.names\n",
    "\n",
    "def build_datetime(df):\n",
    "    if \"datetime\" in df.columns:\n",
    "        return df\n",
    "    if {\"date\", \"time\"}.issubset(df.columns):\n",
    "        ts = pd.to_datetime(df[\"date\"].astype(str) + \" \" +\n",
    "                            df[\"time\"].astype(str),\n",
    "                            errors=\"coerce\")\n",
    "        df = df.assign(datetime=ts)\n",
    "    return df.dropna(subset=[\"datetime\"])\n",
    "\n",
    "def stats(df):\n",
    "    n_pts = len(df)\n",
    "    n_dev = df[\"deviceid\"].nunique()\n",
    "    hrs   = (df[\"datetime\"].max() - df[\"datetime\"].min()\n",
    "            ).total_seconds()/3600\n",
    "    return dict(\n",
    "        n_points=n_pts,\n",
    "        n_devices=n_dev,\n",
    "        avg_pts_per_device=round(n_pts/n_dev, 2) if n_dev else 0,\n",
    "        hours_covered=round(hrs, 2)\n",
    "    )\n",
    "\n",
    "def compare(a, b):\n",
    "    out = {}\n",
    "    for k in a:\n",
    "        before, after = a[k], b[k]\n",
    "        red = round((before - after) / before * 100, 2) if before else None\n",
    "        out[k] = {\"before\": before, \"after\": after, \"reduction_%\": red}\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    for raw in sorted(RAW_DIR.glob(\"*.parquet\")):\n",
    "        binned = BIN_DIR / raw.name\n",
    "        if not binned.exists():\n",
    "            print(f\"⚠️  missing binned file for {raw.name}\")\n",
    "            continue\n",
    "\n",
    "        want_cols = {\"deviceid\", \"date\", \"time\", \"lon\", \"lat\", \"datetime\"}\n",
    "        raw_cols  = want_cols.intersection(columns_in_file(raw))\n",
    "\n",
    "        df_raw = pd.read_parquet(raw, columns=list(raw_cols))\n",
    "        df_raw = build_datetime(df_raw)\n",
    "\n",
    "        df_bin = pd.read_parquet(\n",
    "            binned,\n",
    "            columns=[\"deviceid\", \"datetime\", \"lon\", \"lat\"]\n",
    "        )\n",
    "\n",
    "        s_raw, s_bin = stats(df_raw), stats(df_bin)\n",
    "        comp = compare(s_raw, s_bin)\n",
    "\n",
    "        print(f\"\\n=== {raw.stem} ===\")\n",
    "        pprint({\"raw\": s_raw, \"binned\": s_bin, \"comparison\": comp})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
