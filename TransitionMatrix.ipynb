{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 Parquet files in data_binned\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = Path(\"data_binned\") \n",
    "OUT_DIR = Path(\"data_transitions\")\n",
    "\n",
    "parquet_files = list(IN_DIR.glob(\"*.parquet\"))\n",
    "print(f\"Found {len(parquet_files)} Parquet files in {IN_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 20230331.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (107006496, 12)\n",
      "Time taken to add to the df FROM/TO: 1.73 seconds\n",
      "Total rows: 107006496\n",
      "Rows with either column NaN: 6310405 (5.90%)\n",
      "Valid rows: 100696091 (94.10%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  19.0    19.0     68\n",
      "1         0  19.0   787.0      1\n",
      "2         0  19.0  1435.0      2\n",
      "Saved transitions to data_transitions/20230331.parquet\n",
      "File size: 2.19 MB\n",
      "Total transitions saved: 876922\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 949\n",
      "Unique TO zones: 950\n",
      "Finished processing 20230331.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230328.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (104552132, 12)\n",
      "Time taken to add to the df FROM/TO: 1.77 seconds\n",
      "Total rows: 104552132\n",
      "Rows with either column NaN: 6324635 (6.05%)\n",
      "Valid rows: 98227497 (93.95%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  19.0    19.0     45\n",
      "1         0  19.0  1595.0      1\n",
      "2         0  19.0  2121.0      3\n",
      "Saved transitions to data_transitions/20230328.parquet\n",
      "File size: 2.12 MB\n",
      "Total transitions saved: 849126\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 949\n",
      "Unique TO zones: 948\n",
      "Finished processing 20230328.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230327.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (107185452, 12)\n",
      "Time taken to add to the df FROM/TO: 1.79 seconds\n",
      "Total rows: 107185452\n",
      "Rows with either column NaN: 6311828 (5.89%)\n",
      "Valid rows: 100873624 (94.11%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  19.0    19.0     44\n",
      "1         0  19.0  1595.0      1\n",
      "2         0  19.0  1596.0      1\n",
      "Saved transitions to data_transitions/20230327.parquet\n",
      "File size: 2.10 MB\n",
      "Total transitions saved: 832209\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 948\n",
      "Unique TO zones: 947\n",
      "Finished processing 20230327.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230401.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (93842386, 12)\n",
      "Time taken to add to the df FROM/TO: 1.54 seconds\n",
      "Total rows: 93842386\n",
      "Rows with either column NaN: 5797996 (6.18%)\n",
      "Valid rows: 88044390 (93.82%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  19.0    19.0     26\n",
      "1         0  19.0  2125.0      1\n",
      "2         0  20.0    20.0   3043\n",
      "Saved transitions to data_transitions/20230401.parquet\n",
      "File size: 2.04 MB\n",
      "Total transitions saved: 817796\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 947\n",
      "Unique TO zones: 947\n",
      "Finished processing 20230401.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230329.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (108218727, 12)\n",
      "Time taken to add to the df FROM/TO: 1.76 seconds\n",
      "Total rows: 108218727\n",
      "Rows with either column NaN: 6356635 (5.87%)\n",
      "Valid rows: 101862092 (94.13%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  19.0    19.0     81\n",
      "1         0  19.0   787.0      1\n",
      "2         0  19.0  1595.0      1\n",
      "Saved transitions to data_transitions/20230329.parquet\n",
      "File size: 2.14 MB\n",
      "Total transitions saved: 858845\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 948\n",
      "Unique TO zones: 948\n",
      "Finished processing 20230329.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230330.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (108437587, 12)\n",
      "Time taken to add to the df FROM/TO: 1.75 seconds\n",
      "Total rows: 108437587\n",
      "Rows with either column NaN: 6358788 (5.86%)\n",
      "Valid rows: 102078799 (94.14%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM      TO  count\n",
      "0         0  -1.0  2310.0      1\n",
      "1         0  19.0    19.0     83\n",
      "2         0  19.0  1688.0      4\n",
      "Saved transitions to data_transitions/20230330.parquet\n",
      "File size: 2.14 MB\n",
      "Total transitions saved: 861410\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 947\n",
      "Unique TO zones: 947\n",
      "Finished processing 20230330.parquet\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing 20230402.parquet...\n",
      "Columns: ['deviceid', 'date', 'time', 'lon', 'lat', 'datetime', 'device_change', 'dist_m', 'dt', 'speed_m_s', 'zone_id', 'time_bin']\n",
      "Shape: (89204599, 12)\n",
      "Time taken to add to the df FROM/TO: 1.44 seconds\n",
      "Total rows: 89204599\n",
      "Rows with either column NaN: 5657494 (6.34%)\n",
      "Valid rows: 83547105 (93.66%)\n",
      "df.colums= Index(['time_bin', 'FROM', 'TO', 'count'], dtype='object')\n",
      "\n",
      "First 3 rows of processed dataframe:\n",
      "   time_bin  FROM     TO  count\n",
      "0         0  19.0   19.0    129\n",
      "1         0  19.0   20.0      2\n",
      "2         0  19.0  787.0      1\n",
      "Saved transitions to data_transitions/20230402.parquet\n",
      "File size: 1.87 MB\n",
      "Total transitions saved: 745555\n",
      "Unique time bins: 24\n",
      "Unique FROM zones: 951\n",
      "Unique TO zones: 951\n",
      "Finished processing 20230402.parquet\n",
      "--------------------------------------------------\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "def save_transitions_from_df(df, output_file):\n",
    "    \"\"\"\n",
    "    Save transition data directly from a dataframe with FROM, TO and VALID columns.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with FROM, TO and VALID columns\n",
    "        output_file: Path to save the file\n",
    "        format: 'parquet'\n",
    "        \n",
    "        how it looks like:\n",
    "        time_bin  FROM      TO  count\n",
    "0         0       19.0    19.0     68\n",
    "1         0       19.0   787.0      1\n",
    "2         0       19.0  1435.0      2\n",
    "...\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to only rows with valid transitions\n",
    "    valid_df = df[df['VALID'] == True].copy()\n",
    "    \n",
    "    # Group by time_bin, FROM, TO and count\n",
    "    transitions_df = valid_df.groupby(['time_bin', 'FROM', 'TO']).size().reset_index(name='count')\n",
    "\n",
    "    transitions_df.to_parquet(output_file, compression='snappy')\n",
    "    # Print statistics\n",
    "    file_size = os.path.getsize(output_file) / (1024*1024)\n",
    "    \n",
    "    print(f\"Saved transitions to {output_file}\")\n",
    "    print(f\"File size: {file_size:.2f} MB\")\n",
    "    print(f\"Total transitions saved: {len(transitions_df)}\")\n",
    "    print(f\"Unique time bins: {len(transitions_df['time_bin'].unique())}\")\n",
    "    print(f\"Unique FROM zones: {len(transitions_df['FROM'].unique())}\")\n",
    "    print(f\"Unique TO zones: {len(transitions_df['TO'].unique())}\")\n",
    "    \n",
    "    return transitions_df\n",
    "\n",
    "def create_transition_hashmap(df):\n",
    "    \"\"\"\n",
    "    Create a transition matrix as a nested dictionary (hash map) from the dataframe.\n",
    "    Structure will be: result[time_bin][from_zone][to_zone] = count\n",
    "    \"\"\"\n",
    "    # Initialize the transition hash map\n",
    "    # Structure: transition_map[time_bin][from_zone][to_zone] = count\n",
    "    transition_map = {}\n",
    "    \n",
    "    # Filter to include only valid transitions\n",
    "    valid_df = df[df['VALID'] == True].copy()\n",
    "    \n",
    "    # Print basic stats\n",
    "    total_rows = len(df)\n",
    "    valid_rows = len(valid_df)\n",
    "    print(f\"Total rows in dataframe: {total_rows}\")\n",
    "    print(f\"Valid transitions: {valid_rows} ({valid_rows/total_rows*100:.2f}% of total)\")\n",
    "    \n",
    "    # Process each valid row\n",
    "    for _, row in valid_df.iterrows():\n",
    "        from_zone = row['FROM']  # Using the FROM column\n",
    "        to_zone = row['TO']      # Using the TO column\n",
    "        time_bin = row['time_bin']\n",
    "        \n",
    "        # Initialize nested dictionaries if they don't exist\n",
    "        if time_bin not in transition_map:\n",
    "            transition_map[time_bin] = {}\n",
    "        \n",
    "        if from_zone not in transition_map[time_bin]:\n",
    "            transition_map[time_bin][from_zone] = {}\n",
    "        \n",
    "        # Increment the transition count\n",
    "        if to_zone in transition_map[time_bin][from_zone]:\n",
    "            transition_map[time_bin][from_zone][to_zone] += 1\n",
    "        else:\n",
    "            transition_map[time_bin][from_zone][to_zone] = 1\n",
    "    \n",
    "    # Print transition statistics by time bin\n",
    "    print(\"\\nTransitions by time bin:\")\n",
    "    for time_bin in sorted(transition_map.keys()):\n",
    "        time_bin_transitions = sum(sum(counts.values()) for counts in transition_map[time_bin].values())\n",
    "        print(f\"  Time bin {time_bin}: {time_bin_transitions} transitions ({time_bin_transitions/valid_rows*100:.2f}% of valid)\")\n",
    "    \n",
    "    return transition_map\n",
    "\n",
    "def print_stats(df):\n",
    "    \"\"\"\n",
    "    Calculate and print the percentage of valid and invalid transitions\n",
    "    using the VALID column.\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Count valid transitions (VALID == True)\n",
    "    valid_transitions = df['VALID'].sum()\n",
    "    valid_pct = (valid_transitions / total_rows) * 100\n",
    "\n",
    "    # Count invalid transitions (VALID == False)\n",
    "    invalid_transitions = total_rows - valid_transitions\n",
    "    invalid_pct = (invalid_transitions / total_rows) * 100\n",
    "\n",
    "    print(f\"Total rows: {total_rows}\")\n",
    "    print(f\"Valid transitions: {valid_transitions} ({valid_pct:.2f}%)\")\n",
    "    print(f\"Invalid transitions: {invalid_transitions} ({invalid_pct:.2f}%)\")\n",
    "\n",
    "def create_zone_transitions_sequential_approach1(df):\n",
    "    # Extract arrays from dataframe\n",
    "    zone_ids = df[\"zone_id\"].to_numpy()\n",
    "    time_bins = df[\"time_bin\"].to_numpy()\n",
    "    dc = df[\"device_change\"].to_numpy()\n",
    "    \n",
    "    # Create arrays for the next row's values using roll\n",
    "    zone_next = np.roll(zone_ids, -1)\n",
    "    time_bin_next = np.roll(time_bins, -1)\n",
    "    \n",
    "    # Handle device changes - mark the last row of each device\n",
    "    last_row = np.roll(dc, -1)\n",
    "    last_row[-1] = True  # Last row of the entire dataframe\n",
    "    \n",
    "    # Valid transitions are when:\n",
    "    # 1. Not at a device change boundary\n",
    "    # 2. Time bins are the same\n",
    "    valid_idx = (~last_row) & (time_bins == time_bin_next)\n",
    "    \n",
    "    # Create FROM and TO columns (use NaN for invalid transitions)\n",
    "    from_zones = np.full(len(df), np.nan, dtype=float)\n",
    "    to_zones = np.full(len(df), np.nan, dtype=float)\n",
    "    \n",
    "    # Set values only for valid transitions\n",
    "    from_zones[valid_idx] = zone_ids[valid_idx]\n",
    "    to_zones[valid_idx] = zone_next[valid_idx]\n",
    "    \n",
    "    # Add columns to dataframe\n",
    "    df[\"FROM\"] = from_zones\n",
    "    df[\"TO\"] = to_zones\n",
    "    \n",
    "    # Add VALID column - TRUE when both FROM and TO are not NaN\n",
    "    # This is equivalent to valid_idx\n",
    "    df[\"VALID\"] = valid_idx\n",
    "    \n",
    "    # Add the same_zone column for convenience\n",
    "    df[\"same_zone\"] = (zone_ids == zone_next) & valid_idx\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_zone_transition_matrix_approach1(df):\n",
    "    # Get unique zone_ids and time_bins\n",
    "    unique_zones = df['zone_id'].unique()\n",
    "    time_bins = df['time_bin'].unique()\n",
    "    \n",
    "    # Initialize transition matrices for each time_bin\n",
    "    transition_matrices = {tb: pd.DataFrame(0, index=unique_zones, columns=unique_zones) \n",
    "                          for tb in time_bins}\n",
    "    \n",
    "    # Iterate through rows sequentially\n",
    "    for i in range(len(df) - 1):\n",
    "        current_row = df.iloc[i]\n",
    "        next_row = df.iloc[i + 1]\n",
    "        \n",
    "        # Check if we're still tracking the same device and in the same time bin\n",
    "        if (not next_row['device_change'] and \n",
    "            current_row['time_bin'] == next_row['time_bin']):\n",
    "            \n",
    "            # Get from and to zones\n",
    "            from_zone = current_row['zone_id']\n",
    "            to_zone = next_row['zone_id']\n",
    "            time_bin = current_row['time_bin']\n",
    "            \n",
    "            # Count all transitions, even those between the same zone\n",
    "            transition_matrices[time_bin].loc[from_zone, to_zone] += 1\n",
    "    \n",
    "    return transition_matrices\n",
    "\n",
    "\n",
    "transition_matrices_per_day = []\n",
    "\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# Loop through each file and process it individually\n",
    "for file_path in parquet_files:\n",
    "    print(f\"\\nProcessing {file_path.name}...\")\n",
    "    \n",
    "    # Load the current parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Print information about this file\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    \n",
    "    # Add timer before function call\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform any necessary operations on df here\n",
    "    #transition_matrices_per_day.append(create_zone_transition_matrix_approach1(df))\n",
    "    df = create_zone_transitions_sequential_approach1(df)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Time taken to add to the df FROM/TO: {elapsed_time:.2f} seconds\")\n",
    "    calculate_nan_percentages(df)\n",
    "    \n",
    "    \n",
    "    #start_time = time.time()\n",
    "    #transition_map = create_transition_hashmap(df)\n",
    "    #elapsed_time = time.time() - start_time\n",
    "    #print(f\"Processing transition matrix took: {elapsed_time:.2f} seconds\")\n",
    "    out_path = OUT_DIR / file_path.name\n",
    "\n",
    "    save_transitions_from_df(df, out_path)\n",
    "    # The dataframe will be garbage collected after each iteration\n",
    "    # as it goes out of scope\n",
    "    print(f\"Finished processing {file_path.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
